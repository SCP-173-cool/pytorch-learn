{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hybrid-pittsburgh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dying-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hybrid-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "model_ft = models.densenet121(pretrained=True)\n",
    "num_ftrs = model_ft.classifier.in_features\n",
    "model_ft.classifier = nn.Linear(num_ftrs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "neural-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} (avg: {avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "    \n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target[None])\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].flatten().sum(dtype=torch.float32)\n",
    "            res.append(correct_k * (100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "verified-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseTrainer(object):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        self.train_loader, self.valid_loader = cfg[\"loader\"]\n",
    "        self.batch_size = cfg[\"batch_size\"]\n",
    "        self.model = cfg[\"model\"]\n",
    "        self.device = cfg[\"device\"]\n",
    "        self.optimizer = cfg[\"optimizer\"]\n",
    "        self.criterion = cfg[\"criterion\"]\n",
    "        \n",
    "        self.acc_met = AverageMeter(\"acc\")\n",
    "        self.valid_acc_met = AverageMeter(\"valid_acc\")\n",
    "        \n",
    "    def train_epoch(self, epoch):\n",
    "        \n",
    "        self.model.train()\n",
    "        \n",
    "        for self.idx, (data, target) in enumerate(self.train_loader):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            self.train_step(data, target)\n",
    "        \n",
    "        self.valid()\n",
    "    \n",
    "    def train_step(self, data, target):\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.model(data)\n",
    "        loss = self.criterion(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        self.optimizer.step()\n",
    "        self.acc_met.update(accuracy(output, target)[0].item())\n",
    "        \n",
    "        if (self.idx + 1) % 200 == 0:\n",
    "            print(loss.item())\n",
    "            print(self.acc_met)\n",
    "            \n",
    "            \n",
    "    def valid(self):\n",
    "        self.model.eval()\n",
    "        self.valid_acc_met.reset()\n",
    "        with torch.no_grad():\n",
    "            for data, target in tqdm(self.valid_loader):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.model(data)\n",
    "                \n",
    "                self.valid_acc_met.update(accuracy(output, target)[0].item())\n",
    "        \n",
    "        print(self.valid_acc_met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "practical-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.00001, momentum=0.99)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wrapped-hygiene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 20000 items in train mode.\n",
      "Got 5000 items in valid mode.\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "from data_io import get_dataloader\n",
    "train_lst, valid_lst, train_dataset, valid_dataset, train_loader, valid_loader = get_dataloader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dependent-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config[\"loader\"] = (train_loader, valid_loader)\n",
    "config[\"model\"] = model_ft\n",
    "config[\"device\"] = device\n",
    "config[\"criterion\"] = criterion\n",
    "config[\"optimizer\"] = optimizer_ft\n",
    "config[\"batch_size\"] = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "intensive-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = BaseTrainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "respected-lawyer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31749749183654785\n",
      "acc 84.375000 (avg: 75.429459)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:21<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_acc 100.000000 (avg: 97.982595)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train_epoch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "legislative-flooring",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:07<00:00, 11.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_acc 100.000000 (avg: 96.736551)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-ridge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
